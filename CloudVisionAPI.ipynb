{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CloudVisionAPI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yuki3153/diveintocode-ml/blob/master/CloudVisionAPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW7D94FjIAWv"
      },
      "source": [
        "!pip install --upgrade google-cloud-vision"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFi8V83DNAqE"
      },
      "source": [
        "from google.cloud import vision\n",
        "from google.cloud import storage\n",
        "from google.colab import drive, auth\n",
        "from google.oauth2 import service_account\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.protobuf.json_format import MessageToJson\n",
        "drive.mount('/content/drive')\n",
        "auth.authenticate_user()\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import io\n",
        "import os\n",
        "import shutil\n",
        "import itertools\n",
        "from PIL import Image\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import cv2\n",
        "%cd \"drive/MyDrive/\"\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QchADT5LNMpc"
      },
      "source": [
        "# credentials\n",
        "\n",
        "key_path = os.path.join(os.path.dirname(os.path.abspath(r'credentials/xxx.json')),\n",
        "                        'xxx.json')\n",
        "service_account_info = json.load(open(key_path))\n",
        "credentials = service_account.Credentials.from_service_account_info(service_account_info)\n",
        "\n",
        "storage_client = storage.Client(\n",
        "    credentials=credentials,\n",
        "    project=credentials.project_id,\n",
        ")\n",
        "\n",
        "vision_client = vision.ImageAnnotatorClient(\n",
        "    credentials=credentials\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCI_jDy0UhIe"
      },
      "source": [
        "# function\r\n",
        "\r\n",
        "def pil2cv(image):\r\n",
        "    \"\"\"pillow to cv image\"\"\"\r\n",
        "    image = np.array(image, dtype=np.uint8)\r\n",
        "    if image.ndim == 2:\r\n",
        "        pass\r\n",
        "    elif image.shape[2] == 3:\r\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\r\n",
        "    elif image.shape[2] == 4:\r\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGBA2BGRA)\r\n",
        "    return image\r\n",
        "\r\n",
        "\r\n",
        "def detect_faces(target):\r\n",
        "    \"\"\"Detects faces\"\"\"\r\n",
        "    content = target.download_as_string()\r\n",
        "    vision_image = vision.Image(content=content)\r\n",
        "    response = vision_client.face_detection(image=vision_image)\r\n",
        "    faces = response.face_annotations\r\n",
        "    image = Image.open(io.BytesIO(target.download_as_string()))\r\n",
        "    cv2_image = pil2cv(image)\r\n",
        "    cv2_image = cv2.resize(cv2_image,(300,300))\r\n",
        "    laplacian = cv2.Laplacian(cv2_image, cv2.CV_64F)\r\n",
        "    laplacian = laplacian.var()\r\n",
        "    sub_output['image_size'].append(image.size)\r\n",
        "    sub_output['center_loc'].append((int(image.width/2), int(image.height/2)))\r\n",
        "    image_size = sub_output['image_size'][-1][0] * sub_output['image_size'][-1][1]\r\n",
        "\r\n",
        "    blurred_ = []\r\n",
        "    cnt = 0\r\n",
        "\r\n",
        "    if faces == []: \r\n",
        "        blurred_.append(s)\r\n",
        "        for col in sub_cols[3:-4]:\r\n",
        "            sub_output[col].append(s)\r\n",
        "\r\n",
        "    else:\r\n",
        "        for face in faces:\r\n",
        "            cnt += 1\r\n",
        "            blurred_.append(face.blurred_likelihood)\r\n",
        "            if cnt > 1 :\r\n",
        "                break\r\n",
        "            else:\r\n",
        "                global box\r\n",
        "                box = [(vertex.x, vertex.y) for vertex in face.bounding_poly.vertices]\r\n",
        "                sub_output['roll_angle'].append(face.roll_angle)\r\n",
        "                sub_output['pan_angle'].append(face.pan_angle)\r\n",
        "                sub_output['tilt_angle'].append(face.tilt_angle)\r\n",
        "                sub_output['chin_loc'].append((face.landmarks[30].position.x, face.landmarks[30].position.y))\r\n",
        "                sub_output['forehead_loc'].append((face.landmarks[29].position.x, face.landmarks[29].position.y))\r\n",
        "                sub_output['chin_x_ratio'].append(sub_output['chin_loc'][-1][0] / sub_output['image_size'][-1][0])\r\n",
        "                sub_output['chin_y_ratio'].append(sub_output['chin_loc'][-1][1] / sub_output['image_size'][-1][1])\r\n",
        "                sub_output['forehead_x_ratio'].append(sub_output['forehead_loc'][-1][0] / sub_output['image_size'][-1][0])\r\n",
        "                sub_output['forehead_y_ratio'].append(sub_output['forehead_loc'][-1][1] / sub_output['image_size'][-1][1])\r\n",
        "\r\n",
        "            global face_image\r\n",
        "            face_image = image.crop((box[0][0],box[0][1],box[2][0],box[2][1]))\r\n",
        "            sub_output['face_center_loc'].append(((box[1][0]-box[0][0])/2,(box[2][1]-box[1][1])/2))\r\n",
        "            sub_output['face_image_size'].append(face_image.size)\r\n",
        "            face_size = sub_output['face_image_size'][-1][0] * sub_output['face_image_size'][-1][1]\r\n",
        "            sub_output['area_ratio'].append(face_size/image_size)\r\n",
        "            dist = np.sqrt((sub_output['face_center_loc'][-1][0] - \r\n",
        "                            sub_output['center_loc'][-1][0])**2 + \r\n",
        "                           (sub_output['face_center_loc'][-1][1] - \r\n",
        "                            sub_output['center_loc'][-1][1])**2)\r\n",
        "            sub_output['dist_ratio'].append(dist/sub_output['image_size'][-1][0])\r\n",
        "            \r\n",
        "    return vision_image, image, face_image, blurred_, laplacian, box\r\n",
        "\r\n",
        "\r\n",
        "def detect_labels(image):\r\n",
        "    \"\"\"Detects labels\"\"\"\r\n",
        "    response = vision_client.label_detection(image=image)\r\n",
        "    labels = response.label_annotations\r\n",
        "    \r\n",
        "    label_lst = [label.description for label in labels]\r\n",
        "        \r\n",
        "    return label_lst\r\n",
        "\r\n",
        "\r\n",
        "def detect_properties(face_image):\r\n",
        "    \"\"\"detect image propeties\"\"\"\r\n",
        "    if face_image is None:\r\n",
        "        rgb_median = 0\r\n",
        "        rgb_mean = 0\r\n",
        "    else:\r\n",
        "        img_ = np.asarray(face_image.convert(\"RGB\")).reshape(-1,3)\r\n",
        "        red_median = np.median(img_[:,0])\r\n",
        "        green_median = np.median(img_[:,1])\r\n",
        "        blue_median = np.median(img_[:,2])\r\n",
        "        red_mean = np.mean(img_[:,0])\r\n",
        "        green_mean = np.mean(img_[:,1])\r\n",
        "        blue_mean = np.mean(img_[:,2])\r\n",
        "\r\n",
        "        rgb_median = red_median + green_median + blue_median\r\n",
        "        rgb_mean = red_mean + green_mean + blue_mean\r\n",
        "\r\n",
        "        sub_output['red_median'].append(red_median)\r\n",
        "        sub_output['green_median'].append(green_median)\r\n",
        "        sub_output['blue_median'].append(blue_median)\r\n",
        "        sub_output['red_mean'].append(red_mean)\r\n",
        "        sub_output['green_mean'].append(green_mean)\r\n",
        "        sub_output['blue_mean'].append(blue_mean)\r\n",
        "\r\n",
        "        if red_median == green_median == blue_median:\r\n",
        "            main_output['dark_white'].append('dark_white')\r\n",
        "        else:\r\n",
        "            main_output['dark_white'].append(s)\r\n",
        "        \r\n",
        "    return rgb_median, rgb_mean\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHbS5LW-TH_l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45b5112a-0db3-4b67-b3b9-b6b8c9ef0d79"
      },
      "source": [
        "# cloud storage\r\n",
        "lst=[]\r\n",
        "bucket_name = 'xxx'\r\n",
        "bucket = storage_client.get_bucket(bucket_name)\r\n",
        "buckets = list(storage_client.list_buckets())\r\n",
        "blobs = bucket.list_blobs(prefix = 'xxx/')\r\n",
        "for blob in tqdm(blobs):\r\n",
        "    lst.append(blob.name)\r\n",
        "\r\n",
        "# threshold\r\n",
        "th_face_ratio_max = xx\r\n",
        "th_face_ratio_min = xx\r\n",
        "th_dist = xx\r\n",
        "th_dark = xx\r\n",
        "th_angle = xx\r\n",
        "th_laplacian = xx\r\n",
        "\r\n",
        "# non_val or safe\r\n",
        "s = \"_\"\r\n",
        "\r\n",
        "# detect labels\r\n",
        "mask_labels = [\"Medical equipment\",\"Medical\",\"Mask\"]\r\n",
        "hat_labels = [\"Hat\",\"Headgear\"]\r\n",
        "gesture_labels = [\"Gesture\",\"Finger\"]\r\n",
        "illust_labels = [\"Cartoon\",\"Illustration\"]\r\n",
        "picture_labels = [\"Photograph\"]\r\n",
        "\r\n",
        "# output_path\r\n",
        "drive_root_dir=\"./gdrive/My Drive/\"\r\n",
        "\r\n",
        "# main\r\n",
        "main_output = dict()\r\n",
        "sub_output = dict()\r\n",
        "\r\n",
        "main_cols = [\"image_name\",\"detected_num\",\"position\",\"face_direction\",\r\n",
        "             \"blurred\",\"brightness\",\"frameout\",\"dark_white\",\"illustration\",\"equipment\",\r\n",
        "             \"picture\",\"error_judge\"]\r\n",
        "\r\n",
        "sub_cols = [\"image_name\",\"image_size\",\"center_loc\",\"face_image_size\",\"face_center_loc\",\r\n",
        "            \"dist_ratio\",\"chin_loc\",\"forehead_loc\",\"chin_x_ratio\",\"chin_y_ratio\",\r\n",
        "            \"forehead_x_ratio\",\"forehead_y_ratio\",\"roll_angle\",\"pan_angle\",\"tilt_angle\",\r\n",
        "            \"area_ratio\",\"red_median\",\"green_median\",\"blue_median\",\"red_mean\",\r\n",
        "            \"green_mean\",\"blue_mean\",\"rgb_median\",\"rgb_mean\",\"laplacian\",\"labels\"]\r\n",
        "\r\n",
        "for main, sub in itertools.zip_longest(main_cols, sub_cols):\r\n",
        "    main_output.setdefault(main,[])\r\n",
        "    sub_output.setdefault(sub,[])\r\n",
        "del main_output[None]\r\n",
        "\r\n",
        "for obj in tqdm(lst[1:]):\r\n",
        "    target = bucket.get_blob(obj)\r\n",
        "    name = os.path.basename(obj)\r\n",
        "    main_output[\"image_name\"].append(name)\r\n",
        "    sub_output[\"image_name\"].append(name)\r\n",
        "\r\n",
        "    if target is None:\r\n",
        "        for col in main_cols[2:]:\r\n",
        "            if col != \"error_judge\":\r\n",
        "                main_output[col].append(s)\r\n",
        "            else:\r\n",
        "                main_output[col].append('ERROR')\r\n",
        "        for col in sub_cols[1:]:\r\n",
        "            sub_output[col].append(s)\r\n",
        "    else:\r\n",
        "        face_image = None\r\n",
        "        box = None\r\n",
        "        vision_image, image, face_image, blurred_, laplacian, box = detect_faces(target)\r\n",
        "        label_lst = detect_labels(vision_image)\r\n",
        "        rgb_median, rgb_mean = detect_properties(face_image)\r\n",
        "\r\n",
        "        sub_output['rgb_median'].append(rgb_median)\r\n",
        "        sub_output['rgb_mean'].append(rgb_mean)\r\n",
        "        sub_output['laplacian'].append(laplacian)\r\n",
        "        sub_output['labels'].append(label_lst)\r\n",
        "        \r\n",
        "        if blurred_[0] == 1:\r\n",
        "            face_ratio = int(sub_output['area_ratio'][-1]*100)\r\n",
        "            roll_angle = int(sub_output['roll_angle'][-1]) \r\n",
        "            pan_angle = int(sub_output['pan_angle'][-1])\r\n",
        "            tilt_angle = int(sub_output['tilt_angle'][-1])\r\n",
        "            x = round(sub_output['face_center_loc'][-1][0]*10)\r\n",
        "            y = round(sub_output['face_center_loc'][-1][1]*10)\r\n",
        "            d = round(sub_output['dist_ratio'][-1]*100)\r\n",
        "            main_output['illustration'].append(s)\r\n",
        "\r\n",
        "            if len(blurred_) > 1:\r\n",
        "                main_output['detected_num'].append(len(blurred_))\r\n",
        "            else:\r\n",
        "                main_output['detected_num'].append(1)\r\n",
        "\r\n",
        "            if laplacian <= th_laplacian:\r\n",
        "                main_output['blurred'].append('pint error')\r\n",
        "            else:\r\n",
        "                main_output['blurred'].append(s)\r\n",
        "\r\n",
        "            if pan_angle <= - th_angle or th_angle <= pan_angle:\r\n",
        "                main_output['face_direction'].append('profile')\r\n",
        "            elif roll_angle <= - th_angle or th_angle <= roll_angle:\r\n",
        "                main_output['face_direction'].append('roll')\r\n",
        "            elif tilt_angle <= - th_angle or th_angle <= tilt_angle:\r\n",
        "                main_output['face_direction'].append('vertical')\r\n",
        "            else:\r\n",
        "                main_output['face_direction'].append(s)\r\n",
        "\r\n",
        "            if d >= th_dist or face_ratio < th_face_ratio_min:\r\n",
        "                main_output['position'].append('position error')\r\n",
        "            else:\r\n",
        "                main_output['position'].append(s)\r\n",
        "\r\n",
        "            X = [[sub_output[\"dist_ratio\"][-1],sub_output[\"chin_x_ratio\"][-1],\r\n",
        "                 sub_output[\"chin_y_ratio\"][-1],sub_output[\"forehead_x_ratio\"][-1],\r\n",
        "                 sub_output[\"forehead_y_ratio\"][-1],sub_output[\"area_ratio\"][-1]]]\r\n",
        "            \r\n",
        "            pred = model.predict(X)\r\n",
        "            pred = np.where(pred > 0.5, 1, 0)\r\n",
        "\r\n",
        "            if face_ratio >= th_face_ratio_max:\r\n",
        "                main_output['frameout'].append('frame out')\r\n",
        "            elif pred == 1:\r\n",
        "                main_output['frameout'].append('frame out')\r\n",
        "            else:\r\n",
        "                main_output['frameout'].append(s)\r\n",
        "\r\n",
        "            if rgb_median <= th_dark:\r\n",
        "                main_output['brightness'].append('dark_picture')\r\n",
        "            else:\r\n",
        "                main_output['brightness'].append(s)\r\n",
        "            \r\n",
        "            if any(l in label_lst for l in mask_labels):\r\n",
        "                main_output['equipment'].append('Mask')\r\n",
        "            elif any(l in label_lst for l in hat_labels):\r\n",
        "                main_output['equipment'].append('Hat')\r\n",
        "            elif any(l in label_lst for l in gesture_labels):\r\n",
        "                main_output['equipment'].append('Gesture')\r\n",
        "            else:\r\n",
        "                main_output['equipment'].append(s)\r\n",
        "            \r\n",
        "            if any(l in label_lst for l in picture_labels):\r\n",
        "                main_output['picture'].append('picture')\r\n",
        "            else:\r\n",
        "                main_output['picture'].append(s)\r\n",
        "\r\n",
        "            agg_lst = [main_output[col][-1] for col in main_cols[3:-1]]\r\n",
        "            if main_output['detected_num'][-1] ==1 and len(list(set(agg_lst)))==1:\r\n",
        "                main_output['error_judge'].append(s)\r\n",
        "            else:\r\n",
        "                main_output['error_judge'].append('ERROR')\r\n",
        "\r\n",
        "            if main_output['error_judge'][-1] == 'ERROR':\r\n",
        "                image.save(drive_root_dir +str(name),'PNG')\r\n",
        "\r\n",
        "        else:\r\n",
        "            for col in main_cols[2:8]:\r\n",
        "                main_output[col].append(s)\r\n",
        "            main_output['equipment'].append(s)\r\n",
        "            main_output['picture'].append(s)\r\n",
        "            main_output['error_judge'].append('ERROR')\r\n",
        "            image.save(drive_root_dir + str(name),'')\r\n",
        "\r\n",
        "            if 'Text' in label_lst and 'Font' in label_lst and 'Line' in label_lst:\r\n",
        "                main_output['meishi'].append('Meishi')\r\n",
        "            else:\r\n",
        "                main_output['meishi'].append('_')\r\n",
        "\r\n",
        "            if any(l in label_lst for l in illust_labels):\r\n",
        "                main_output['illustration'].append('illustration picture')\r\n",
        "            else:\r\n",
        "                main_output['illustration'].append(s)\r\n",
        "\r\n",
        "# output\r\n",
        "main_df = pd.DataFrame(main_output.values(), index=main_output.keys()).T\r\n",
        "sub_df = pd.DataFrame(sub_output.values(), index=sub_output.keys()).T\r\n",
        "print(main_df.shape)\r\n",
        "print(sub_df.shape)\r\n",
        "\r\n",
        "main_df.to_excel(drive_root_dir+'main_output.xlsx',encoding=\"utf-8\")\r\n",
        "sub_df.to_excel(drive_root_dir+'sub_output.xlsx',encoding=\"utf-8\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [14:43<00:00,  1.13it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc1zEcPvAEqg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpIB5o8MJfro"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}